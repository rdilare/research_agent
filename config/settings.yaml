# Research Assistant Agent Configuration - Standard LangChain/LangGraph Setup

# LLM Configuration
llm:
  model: "llama3.2:3b"
  # model: "gemma3:4b"
  base_url: "http://localhost:11434"
  temperature: 0.7

# Data Sources Configuration  
data_sources:
  arxiv:
    enabled: true
    max_results: 5
  duckduckgo:
    enabled: true
    max_results: 5
    extract_full_content: true
  
# Logging Configuration
logging:
  level: "INFO"
  debug_mode: true
  step_logging: true
  
# Retrieval Configuration
retrieval:
  max_results: 5
  search_kwargs:
    k: 3
